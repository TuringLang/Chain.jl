var documenterSearchIndex = {"docs":
[{"location":"diagnostics.html#Diagnostics","page":"Diagnostics","title":"Diagnostics","text":"","category":"section"},{"location":"diagnostics.html","page":"Diagnostics","title":"Diagnostics","text":"Modules = [MCMCChains]\nPages = [\n  \"discretediag.jl\",\n  \"gelmandiag.jl\",\n  \"gewekediag.jl\",\n  \"heideldiag.jl\",\n  \"rafterydiag.jl\",\n  \"rstar.jl\",\n  \"ess.jl\"\n]","category":"page"},{"location":"diagnostics.html#MCMCChains.weiss-Tuple{AbstractMatrix{T} where T}","page":"Diagnostics","title":"MCMCChains.weiss","text":"weiss(X::AbstractMatrix)\n\nThe weiss procedure to assess convergence in MCMC output computes fracX^2c and evaluates a p-value from the X^2 (Chi-square) distribution with (R  1)(s  1) degrees of freedom.\n\n\n\n\n\n","category":"method"},{"location":"diagnostics.html#MCMCChains.gelmandiag-Tuple{AbstractArray{var\"#s11\", 3} where var\"#s11\"<:Real}","page":"Diagnostics","title":"MCMCChains.gelmandiag","text":"gelmandiag(chains; kwargs...)\n\n\nGelman, Rubin and Brooks Diagnostics.\n\n\n\n\n\n","category":"method"},{"location":"diagnostics.html#MCMCChains.gelmandiag-Tuple{AbstractArray{var\"#s48\", 3} where var\"#s48\"<:Real}","page":"Diagnostics","title":"MCMCChains.gelmandiag","text":"gelmandiag(chains::AbstractArray{<:Real,3}; kwargs...)\n\nGelman, Rubin and Brooks Diagnostics.\n\n\n\n\n\n","category":"method"},{"location":"diagnostics.html#MCMCChains.gelmandiag_multivariate-Tuple{AbstractArray{var\"#s48\", 3} where var\"#s48\"<:Real}","page":"Diagnostics","title":"MCMCChains.gelmandiag_multivariate","text":"gelmandiag_multivariate(chains::AbstractArray{<:Real,3}; kwargs...)\n\n\n\n\n\n","category":"method"},{"location":"diagnostics.html#MCMCChains.gewekediag-Tuple{Chains}","page":"Diagnostics","title":"MCMCChains.gewekediag","text":"gewekediag(chains; sections, first, last, etype, kwargs...)\n\n\nGeweke Diagnostic.\n\n\n\n\n\n","category":"method"},{"location":"diagnostics.html#MCMCChains.heideldiag-Tuple{Chains}","page":"Diagnostics","title":"MCMCChains.heideldiag","text":"heideldiag(chains; sections, alpha, eps, etype, kwargs...)\n\n\nHeidelberger and Welch Diagnostic\n\n\n\n\n\n","category":"method"},{"location":"diagnostics.html#MCMCChains.heideldiag-Tuple{Vector{var\"#s48\"} where var\"#s48\"<:Real}","page":"Diagnostics","title":"MCMCChains.heideldiag","text":"heideldiag(x::Vector{<:Real}; alpha, eps, etype, start, args...)\nheideldiag(chains::Chains; sections, alpha, eps, etype, args...)\n\nHeidelberger and Welch Diagnostic\n\n\n\n\n\n","category":"method"},{"location":"diagnostics.html#MCMCChains.rafterydiag-Tuple{Vector{var\"#s48\"} where var\"#s48\"<:Real}","page":"Diagnostics","title":"MCMCChains.rafterydiag","text":"rafterydiag(x::Vector{<:Real}; q, r, s, eps, range)\nrafterydiag(chains::Chains; sections, q, r, s, eps)\n\nRaftery and Lewis Diagnostic.\n\n\n\n\n\n","category":"method"},{"location":"diagnostics.html#MCMCChains.rstar-Tuple{Random.AbstractRNG, MLJModelInterface.Supervised, AbstractMatrix{T} where T, AbstractVector{Int64}}","page":"Diagnostics","title":"MCMCChains.rstar","text":"rstar([rng ,]classif::Supervised, chains::Chains; kwargs...)\nrstar([rng ,]classif::Supervised, x::AbstractMatrix, y::AbstractVector; kwargs...)\n\nCompute the R* convergence diagnostic of MCMC.\n\nThis implementation is an adaption of Algorithm 1 & 2, described by Lambert & Vehtari (2020). Note that the correctness of the statistic depends on the convergence of the classifier used internally in the statistic. You can inspect the training of the classifier by adjusting the verbosity level.\n\nKeyword Arguments\n\nsubset = 0.8 ... Subset used to train the classifier, i.e. 0.8 implies 80% of the samples are used.\niterations = 10 ... Number of iterations used to estimate the statistic. If the classifier is not probabilistic, i.e. does not return class probabilities, it is advisable to use a value of one.\nverbosity = 0 ... Verbosity level used during fitting of the classifier.\n\nUsage\n\n# Load an MLJ classifier to compute the statistic, e.g., the XGBoost classifier.\nusing MLJModels\nXGBoost = @load XGBoostClassifier\n\n# Compute 20 samples of the R* statistic using sampling according to the prediction probabilities.\nRs = rstar(XGBoost(), chn; iterations=20)\n\n# estimate Rstar\nR = mean(Rs)\n\n# visualize distribution\nhistogram(Rs)\n\n\n\n\n\n","category":"method"},{"location":"diagnostics.html#MCMCChains.BDAESSMethod","page":"Diagnostics","title":"MCMCChains.BDAESSMethod","text":"BDAESSMethod <: AbstractESSMethod\n\nThe BDAESSMethod uses a standard algorithm for estimating the effective sample size of MCMC chains.\n\nIt is is based on the discussion by Vehtari et al. (2019) and uses the variogram estimator of the autocorrelation function discussed in  Bayesian Data Analysis (2013).\n\n\n\n\n\n","category":"type"},{"location":"diagnostics.html#MCMCChains.ESSMethod","page":"Diagnostics","title":"MCMCChains.ESSMethod","text":"ESSMethod <: AbstractESSMethod\n\nThe ESSMethod uses a standard algorithm for estimating the effective sample size of MCMC chains.\n\nIt is is based on the discussion by Vehtari et al. (2019) and uses a biased estimator of the autocovariance, as discussed by Geyer (1992). In contrast to Geyer, the divisor n - 1 is used in the estimation of the autocovariance to obtain the unbiased estimator of the variance for lag 0.\n\n\n\n\n\n","category":"type"},{"location":"diagnostics.html#MCMCChains.FFTESSMethod","page":"Diagnostics","title":"MCMCChains.FFTESSMethod","text":"FFTESSMethod <: AbstractESSMethod\n\nThe FFTESSMethod uses a standard algorithm for estimating the effective sample size of MCMC chains.\n\nIt is is based on the discussion by Vehtari et al. (2019) and uses the biased estimator of the autocovariance, as discussed by Geyer (1992). In contrast to Geyer, the divisor n - 1 is used in the estimation of the autocovariance to obtain the unbiased estimator of the variance for lag 0.\n\nIn contrast to ESSMethod, this method uses fast Fourier transforms (FFTs) for estimating the autocorrelation.\n\n\n\n\n\n","category":"type"},{"location":"diagnostics.html#MCMCChains.copyto_split!-Tuple{AbstractMatrix{T} where T, AbstractMatrix{T} where T}","page":"Diagnostics","title":"MCMCChains.copyto_split!","text":"copyto_split!(out::AbstractMatrix, x::AbstractMatrix)\n\nCopy the elements of matrix x to matrix out, in which each column of x is split.\n\nIf the number of rows in x is odd, the sample at index (size(x, 1) + 1) / 2 is dropped.\n\n\n\n\n\n","category":"method"},{"location":"diagnostics.html#MCMCChains.ess-Tuple{Chains}","page":"Diagnostics","title":"MCMCChains.ess","text":"ess(chains::Chains; kwargs...)\n\nEstimate the effective sample size and the potential scale reduction.\n\n\n\n\n\n","category":"method"},{"location":"index.html#MCMCChains","page":"MCMCChains","title":"MCMCChains","text":"","category":"section"}]
}
